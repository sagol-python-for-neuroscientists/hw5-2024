import pathlib
from typing import Tuple, Union
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd


class QuestionnaireAnalysis:
    """Reads and analyzes data generated by the questionnaire experiment.
    Should be able to accept strings and pathlib.Path objects.

    Usage: "read_data" loads the data into memory, and the rest of the methods
    can be called out of order as they assume that the data is already in
    self.data.
    """

    def __init__(self, data_fname: Union[pathlib.Path, str]):
        # Initialize the class and verify the file path
        
        try:
            self.data_fname = pathlib.Path(data_fname).resolve()
            
        except TypeError:
            print("ERROR: Please provide a string or a pathlib.Path.")
            raise
        
        if not self.data_fname.exists():
            raise ValueError(f"The specified file does not exist.")

    def read_data(self):
        """Reads the json data located in self.data_fname into memory, to
        the attribute self.data.
        """
        self.data = pd.read_json(self.data_fname)

    def show_age_distrib(self) -> Tuple[np.ndarray, np.ndarray]:
        """
        Calculates and plots the age distribution of the participants.

        Returns
        -------
        hist : np.ndarray
            Number of people in a given bin
        bins : np.ndarray
            Bin edges
        """
        # Convert ages to numeric, replacing errors with NaN
        self.data['age'] = pd.to_numeric(self.data['age'], errors='coerce')
        # Filter out NaN ages
        val_ages = self.data['age'].dropna()

        # Define bin edges for histogram
        bins = np.arange(0, 101, 10)
        # Compute histogram of ages
        hist, bins = np.histogram(val_ages, bins=bins)
        
                # Plotting logic (commented out)
                # plt.hist(val_ages, bins=bins, edgecolor='black')
                # plt.xlabel('Age')  
                # plt.ylabel('Number of Participants') 
                # plt.title('Age Distribution of Participants') 
                # plt.show() 

        return hist, bins

    def remove_rows_without_mail(self) -> pd.DataFrame:
        """Checks self.data for rows with invalid emails, and removes them.

        Returns
        -------
        pd.DataFrame
            A corrected DataFrame, i.e. the same table but with the erroneous rows removed and
            the (ordinal) index after a reset.
        """
        # List to store indices of valid emails
        ind_valid_mail = []

        # Iterate over each email and check validity
        for i, mail in enumerate(self.data["email"]):
            if self._validate_email(mail):
                ind_valid_mail.append(i)

        # Select rows with valid emails and reset index
        valid_mails_df = self.data.loc[ind_valid_mail]
        valid_mails_df = valid_mails_df.reset_index(drop=True)
        return valid_mails_df

    def _validate_email(self, email: str) -> bool:
        """Checks if an email is valid.

        Parameters
        ----------
        email : str
            The string to validate

        Returns
        -------
        bool
            True if email is valid, False otherwise
        """
        # Conditions for email validation
        if "@" not in email or "." not in email:
            return False
        
        if email.startswith(".") or email.startswith("@") or email.endswith(".") or email.endswith("@"):
            return False
        
        if not email.isascii():
            return False
        
        if email.count("@") != 1 or email[email.find("@") + 1] == ".":
            return False
        
        return True

    def _find_rows_with_nulls(self) -> np.ndarray:
        """Finds rows which contain at least one NA
        and returns their index as an array.

        Returns
        -------
        np.ndarray
            Indices of rows with at least one NA.
        """
        question_data = self.data.loc[:, "q1":"q5"]
        nan_rows = question_data[question_data.isna().any(axis=1)].index.to_numpy()
        return nan_rows

    def fill_na_with_mean(self) -> Tuple[pd.DataFrame, np.ndarray]:
        """
        Finds the subjects that didn't answer all questions and replaces
        missing values with the mean of the other grades for that student.

        Returns
        -------
        2-tuple of (pd.DataFrame, np.ndarray)
            The corrected DataFrame after insertion of the mean grade and row
            indices of the students whose new grades were generated.
        """
        # Identify rows with any missing values
        null_indices = self.data.loc[:, "q1":"q5"].isna().any(axis=1).to_numpy().nonzero()[0]
        # Copy question data
        question_scores = self.data.loc[:, "q1":"q5"].copy()

        # Replace missing values with the mean of each row
        for i in range(len(question_scores)):
            row_mean = question_scores.iloc[i].mean()
            question_scores.iloc[i] = question_scores.iloc[i].fillna(row_mean)

        # Update original data with modified question scores
        upd_data = self.data.copy()
        upd_data.loc[:, "q1":"q5"] = question_scores
        return upd_data, null_indices

    def score_subjects(self, maximal_nans_per_sub: int = 1) -> pd.DataFrame:
        """Calculates the average score of a subject and adds a new "score" column
        with it.

        If the subject has more than "maximal_nans_per_sub" NaN in his grades, the
        score should be NA. Otherwise, the score is simply the mean of the other grades.
        The datatype of score should be 'UInt8', and the floating point raw numbers should be
        rounded down before the conversion.

        Parameters
        ----------
        maximal_nans_per_sub : int, optional
            Number of allowed NaNs per subject before giving a NA score.

        Returns
        -------
        pd.DataFrame
            A new DF with a new column - "score".
        """
        question_data = self.data.loc[:, "q1":"q5"]
        calculated_scores = []

        # Compute score for each row
        for index, row in question_data.iterrows():
            missing_count = row.isna().sum()

            # Assign NaN if missing values exceed limit
            if missing_count > maximal_nans_per_sub:
                calculated_scores.append(pd.NA)
            else:
                mean_score = int(row.mean())
                calculated_scores.append(mean_score)

        # Add calculated scores to the DataFrame
        self.data["score"] = pd.Series(calculated_scores, dtype="UInt8")
        return self.data

    def correlate_gender_age(self) -> pd.DataFrame:
        """Looks for a correlation between the gender of the subject, their age
        and the score for all five questions.

        Returns
        -------
        pd.DataFrame
            A DataFrame with a MultiIndex containing the gender and whether the subject is above
            40 years of age, and the average score in each of the five questions.
        """
        # Drop rows with missing ages
        age_filtered_data = self.data.dropna(axis=0, subset=["age"])

        # Set MultiIndex with gender and age
        indexed_data = age_filtered_data.set_index(["gender", "age"], append=True)

        # Select question columns
        question_subset = indexed_data.loc[:, "q1":"q5"]

        # Group by gender and age category (>40 or <=40)
        grouped_data = question_subset.groupby([None, lambda age: age > 40], level=[1, 2])

        # Calculate mean scores for each group
        mean_scores = grouped_data.mean()

        return mean_scores